{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e32d17e-4bba-4dc3-94b4-c410d6f37841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      ":: loading settings :: url = jar:file:/home/pol/dev/zajecia/pyspark-graphs/.venv/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /home/pol/.ivy2.5.2/cache\n",
      "The jars for the packages stored in: /home/pol/.ivy2.5.2/jars\n",
      "io.graphframes#graphframes-spark4_2.13 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-fbdf30f9-3c64-482f-aef3-9dbdb407451e;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.graphframes#graphframes-spark4_2.13;0.10.0 in central\n",
      "\tfound io.graphframes#graphframes-graphx-spark4_2.13;0.10.0 in central\n",
      ":: resolution report :: resolve 65ms :: artifacts dl 2ms\n",
      "\t:: modules in use:\n",
      "\tio.graphframes#graphframes-graphx-spark4_2.13;0.10.0 from central in [default]\n",
      "\tio.graphframes#graphframes-spark4_2.13;0.10.0 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-fbdf30f9-3c64-482f-aef3-9dbdb407451e\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/3ms)\n",
      "26/01/12 17:03:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+\n",
      "| id|   name|age|\n",
      "+---+-------+---+\n",
      "|  a|  Alice| 34|\n",
      "|  b|    Bob| 36|\n",
      "|  c|Charlie| 37|\n",
      "|  d|  David| 29|\n",
      "|  e| Esther| 32|\n",
      "|  f|  Fanny| 38|\n",
      "|  g|  Gabby| 60|\n",
      "+---+-------+---+\n",
      "\n",
      "+---+---+------------+\n",
      "|src|dst|relationship|\n",
      "+---+---+------------+\n",
      "|  a|  b|      friend|\n",
      "|  b|  c|      follow|\n",
      "|  c|  b|      follow|\n",
      "|  f|  c|      follow|\n",
      "|  e|  f|      follow|\n",
      "|  e|  d|      friend|\n",
      "|  d|  a|      friend|\n",
      "|  a|  e|      friend|\n",
      "|  g|  e|      follow|\n",
      "+---+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from graphframes import GraphFrame\n",
    "import os\n",
    "#spark=SparkSession.builder.appName(\"graph\").master(\"local[*]\").getOrCreate()\n",
    "\n",
    "spark = SparkSession.builder.appName(\"graphs\")\\\n",
    "        .config('spark.jars.packages', 'io.graphframes:graphframes-spark4_2.13:0.10.0')\\\n",
    "        .master(\"local[*]\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "vertics = spark.createDataFrame([\n",
    "  (\"a\", \"Alice\", 34),\n",
    "  (\"b\", \"Bob\", 36),\n",
    "  (\"c\", \"Charlie\", 37),\n",
    "  (\"d\", \"David\", 29),\n",
    "  (\"e\", \"Esther\", 32),\n",
    "  (\"f\", \"Fanny\", 38),\n",
    "  (\"g\", \"Gabby\", 60)\n",
    "], [\"id\", \"name\", \"age\"])\n",
    "\n",
    "\n",
    "# Edges DataFrame\n",
    "edges = spark.createDataFrame([\n",
    "  (\"a\", \"b\", \"friend\"),\n",
    "  (\"b\", \"c\", \"follow\"),\n",
    "  (\"c\", \"b\", \"follow\"),\n",
    "  (\"f\", \"c\", \"follow\"),\n",
    "  (\"e\", \"f\", \"follow\"),\n",
    "  (\"e\", \"d\", \"friend\"),\n",
    "  (\"d\", \"a\", \"friend\"),\n",
    "  (\"a\", \"e\", \"friend\"),\n",
    "  (\"g\", \"e\", \"follow\")\n",
    "], [\"src\", \"dst\", \"relationship\"])\n",
    "\n",
    "# Create a GraphFrame\n",
    "g = GraphFrame(vertics, edges)\n",
    "g.vertices.show()\n",
    "g.edges.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73498abb-b2be-492f-b115-7de6e7d3f411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/12 17:04:54 WARN AggregateMessages: Returned DataFrame is persistent and materialized!\n",
      "26/01/12 17:04:57 WARN TriangleCount$: Returned DataFrame is persistent and materialized!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+----+------------+----+------------+-----+\n",
      "| id|   name|age| src|src_triplets| dst|dst_triplets|count|\n",
      "+---+-------+---+----+------------+----+------------+-----+\n",
      "|  g|  Gabby| 60|NULL|        NULL|NULL|        NULL|    0|\n",
      "|  f|  Fanny| 38|NULL|        NULL|NULL|        NULL|    0|\n",
      "|  e| Esther| 32|NULL|        NULL|   e|           2|    1|\n",
      "|  d|  David| 29|   d|           1|   d|           1|    1|\n",
      "|  c|Charlie| 37|NULL|        NULL|NULL|        NULL|    0|\n",
      "|  b|    Bob| 36|NULL|        NULL|NULL|        NULL|    0|\n",
      "|  a|  Alice| 34|   a|           2|NULL|        NULL|    1|\n",
      "+---+-------+---+----+------------+----+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from graphframes.classic.graphframe import StorageLevel\n",
    "results = g.triangleCount(storage_level=StorageLevel.MEMORY_ONLY)\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af4b801-2076-4c37-81d2-43bc1ce735fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = g.shortestPaths(landmarks=['a', 'c'])\n",
    "results.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
